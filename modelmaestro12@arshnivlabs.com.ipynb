{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Likelihood of a Completed Purchase Using Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In retail, predicting the likelihood that a customer will complete a purchase is crucial for optimizing sales strategies, managing inventory, and personalizing customer experiences. Given a dataset of product sales, customer demographics, and promotional campaigns, the task is to predict whether a transaction will result in a completed purchase (binary outcome: Yes/No). The goal is to develop classification models that estimate the probability of a customer completing their order based on various features, such as product pricing, customer demographics, and promotional offers. \n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "Develop various classification models that predict the likelihood of a purchase being completed, given the customer and product features.  \n",
    "\n",
    "The task is to predict the likelihood that a transaction will result in a completed purchase based on features such as: \n",
    "\n",
    "- Customer ID: A unique identifier for each customer. \n",
    "\n",
    "- Age: The customer's age, which could influence buying patterns. \n",
    "\n",
    "- Gender: The gender of the customer (Male/Female). \n",
    "\n",
    "- Loyalty Member: Whether the customer is a member of the loyalty program (Yes/No), which could indicate higher engagement or likelihood to complete a purchase. \n",
    "\n",
    "- Product Type: The category or type of product purchased (e.g., Electronics, Apparel), which might correlate with purchase completion rates. \n",
    "\n",
    "- SKU: Unique identifier for the product (Stock Keeping Unit). \n",
    "\n",
    "- Rating: The average product rating (1-5), which could influence the customer's decision to complete the purchase. \n",
    "\n",
    "- Order Status: Indicates whether the order was completed, pending, or canceled. For this model, the target will be whether the order was completed (Yes/No). \n",
    "\n",
    "- Payment Method: The method of payment used (e.g., Credit Card, PayPal), which may influence the probability of a transaction being completed. \n",
    "\n",
    "- Unit Price: The price per unit of the product, as higher-priced items may have lower conversion rates. \n",
    "\n",
    "- Quantity: The number of units purchased in the order. \n",
    "\n",
    "- Purchase Date: The date when the purchase was made, which might capture time-related patterns in purchase behavior. \n",
    "\n",
    "- Shipping Type: The shipping method chosen by the customer (e.g., Standard, Expedited), which could be linked to the likelihood of completing the order. \n",
    "\n",
    "- Add-ons Purchased: Whether the customer bought additional items (e.g., accessories, warranties) along with the main product (Yes/No). \n",
    "\n",
    "- Add-on Total: The total cost of any add-ons purchased, which contributes to the final price and may influence purchase completion. \n",
    "\n",
    "**The goal is to predict the probability that a customer will complete a transaction, which will be modelled as a binary outcome:** \n",
    "\n",
    "**Approach Overview:**\n",
    "\n",
    "- Data Preprocessing: \n",
    "\n",
    "Clean the data, handling missing values, encoding categorical variables, and ensuring that only completed orders are used in the target variable. \n",
    "\n",
    "Create a binary target variable: 1 for completed orders, 0 for non-completed orders. \n",
    "\n",
    "- Feature Engineering: \n",
    "\n",
    "Engineer features from the raw data, such as creating binary variables for Add-ons Purchased or Loyalty Member status. \n",
    "\n",
    "Normalize or scale continuous features like Unit Price and Quantity if necessary. \n",
    "\n",
    "- Model Training: \n",
    "\n",
    "Split the dataset into training and testing sets. \n",
    "\n",
    "Train the classification models on the training data to predict the binary outcome of purchase completion. \n",
    "\n",
    "- Model Evaluation: \n",
    "\n",
    "Use metrics such as accuracy, precision, recall, and AUC-ROC to evaluate model performance. \n",
    "\n",
    "- Prediction: \n",
    "\n",
    "Use the trained classification models to predict the likelihood of purchase completion for future transactions. \n",
    "\n",
    "- Conclusion:  \n",
    "\n",
    "Choose the best model based on efficiency in solving the business problem##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lib\"></a>\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 'Pandas' \n",
    "import pandas as pd \n",
    "\n",
    "# import 'Numpy' \n",
    "import numpy as np\n",
    "\n",
    "# import subpackage of Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# import 'Seaborn' \n",
    "import seaborn as sns\n",
    "\n",
    "# to suppress warnings \n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# display all columns of the dataframe\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# display all rows of the dataframe\n",
    "pd.options.display.max_rows = None\n",
    " \n",
    "# to display the float values upto 6 decimal places     \n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "\n",
    "# import train-test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import various functions from statsmodels\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# import StandardScaler to perform scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# import various functions from sklearn \n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the plot size using 'rcParams'\n",
    "plt.rcParams['figure.figsize'] = [15,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load the dataset and perform preliminary EDA (Exploratory Data Analysis) with key observations and insights- (weightage - 20 marks)â€¯(AE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prep\"></a>\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.1 Load the Sales dataset. (weightage - 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Loyalty Member</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Total Price</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Purchase Date</th>\n",
       "      <th>Shipping Type</th>\n",
       "      <th>Add-ons Purchased</th>\n",
       "      <th>Add-on Total</th>\n",
       "      <th>Order Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Smartphone</td>\n",
       "      <td>SKU1004</td>\n",
       "      <td>2</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>5538.330000</td>\n",
       "      <td>791.190000</td>\n",
       "      <td>7</td>\n",
       "      <td>20-03-2024</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Accessory,Accessory,Accessory</td>\n",
       "      <td>40.210000</td>\n",
       "      <td>Cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>SKU1002</td>\n",
       "      <td>3</td>\n",
       "      <td>Paypal</td>\n",
       "      <td>741.090000</td>\n",
       "      <td>247.030000</td>\n",
       "      <td>3</td>\n",
       "      <td>20-04-2024</td>\n",
       "      <td>Overnight</td>\n",
       "      <td>Impulse Item</td>\n",
       "      <td>26.090000</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>SKU1005</td>\n",
       "      <td>3</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>1855.840000</td>\n",
       "      <td>463.960000</td>\n",
       "      <td>4</td>\n",
       "      <td>17-10-2023</td>\n",
       "      <td>Express</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002</td>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Smartphone</td>\n",
       "      <td>SKU1004</td>\n",
       "      <td>2</td>\n",
       "      <td>Cash</td>\n",
       "      <td>3164.760000</td>\n",
       "      <td>791.190000</td>\n",
       "      <td>4</td>\n",
       "      <td>08-09-2024</td>\n",
       "      <td>Overnight</td>\n",
       "      <td>Impulse Item,Impulse Item</td>\n",
       "      <td>60.160000</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>75</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Smartphone</td>\n",
       "      <td>SKU1001</td>\n",
       "      <td>5</td>\n",
       "      <td>Cash</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>21-05-2024</td>\n",
       "      <td>Express</td>\n",
       "      <td>Accessory</td>\n",
       "      <td>35.560000</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID  Age Gender Loyalty Member Product Type      SKU  Rating  \\\n",
       "0         1000   53   Male             No   Smartphone  SKU1004       2   \n",
       "1         1000   53   Male             No       Tablet  SKU1002       3   \n",
       "2         1002   41   Male             No       Laptop  SKU1005       3   \n",
       "3         1002   41   Male            Yes   Smartphone  SKU1004       2   \n",
       "4         1003   75   Male            Yes   Smartphone  SKU1001       5   \n",
       "\n",
       "  Payment Method  Total Price  Unit Price  Quantity Purchase Date  \\\n",
       "0    Credit Card  5538.330000  791.190000         7    20-03-2024   \n",
       "1         Paypal   741.090000  247.030000         3    20-04-2024   \n",
       "2    Credit Card  1855.840000  463.960000         4    17-10-2023   \n",
       "3           Cash  3164.760000  791.190000         4    08-09-2024   \n",
       "4           Cash    41.500000   20.750000         2    21-05-2024   \n",
       "\n",
       "  Shipping Type              Add-ons Purchased  Add-on Total Order Status  \n",
       "0      Standard  Accessory,Accessory,Accessory     40.210000    Cancelled  \n",
       "1     Overnight                   Impulse Item     26.090000    Completed  \n",
       "2       Express                            NaN      0.000000    Completed  \n",
       "3     Overnight      Impulse Item,Impulse Item     60.160000    Completed  \n",
       "4       Express                      Accessory     35.560000    Completed  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv file\n",
    "def read_dataset (data): \n",
    "   # code starts here\n",
    "  df = pd.read_csv(data)\n",
    "  return df\n",
    "   # code ends here\n",
    "path = \"retail_sales.csv\"\n",
    "df_sales = read_dataset(path)\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.2â€¯ Check the shape and data types. (weightage - 1 mark)â€¯ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 16)\n"
     ]
    }
   ],
   "source": [
    "# use 'shape' to check the dimension of data\n",
    "def df_shape(df_sales):\n",
    "    # code starts here \n",
    "    s = df_sales.shape\n",
    "    \n",
    "    return s\n",
    "    # code ends here\n",
    "df_shape = df_shape(df_sales)\n",
    "print(df_shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dtype\"></a>\n",
    "#### Check the Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID            int64\n",
      "Age                    int64\n",
      "Gender                object\n",
      "Loyalty Member        object\n",
      "Product Type          object\n",
      "SKU                   object\n",
      "Rating                 int64\n",
      "Payment Method        object\n",
      "Total Price          float64\n",
      "Unit Price           float64\n",
      "Quantity               int64\n",
      "Purchase Date         object\n",
      "Shipping Type         object\n",
      "Add-ons Purchased     object\n",
      "Add-on Total         float64\n",
      "Order Status          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# use 'dtypes' to check the data type of a variable\n",
    "# use 'shape' to check the dimension of data\n",
    "def df_dtypes(df):\n",
    "    # code starts here\n",
    "    d = df.dtypes\n",
    "    return d\n",
    "    # code ends here\n",
    "df_dtypes = df_dtypes(df_sales)\n",
    "print(df_dtypes)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.3â€¯Â Remove the given variables namely, Customer ID, SKU ,Purchase Date and Unit PriceÂ (weightage - 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['C'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# code ends here\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_sales = \u001b[43mdrop_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sales\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m df_sales.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mdrop_columns\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# code starts here\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-venv/lib/python3.12/site-packages/pandas/core/frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-venv/lib/python3.12/site-packages/pandas/core/generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-venv/lib/python3.12/site-packages/pandas/core/generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter-venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['C'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# drop the column using drop()\n",
    "def drop_columns(df) : \n",
    "    cols = ['Customer ID', 'SKU','Purchase Date','Unit Price']\n",
    "    # code starts here\n",
    "    for i in cols:\n",
    "        df = df.drop()\n",
    "        return\n",
    "    return\n",
    "    # code ends here\n",
    "df_sales = drop_columns(df_sales)\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.4â€¯Â Draw box plots to check for outliers for numeric variables, namely: Age, Rating, Total Price, Quantity and Add-on Totalâ€¯Â \n",
    "\n",
    "- Run â€˜describeâ€™ function to get the descriptive statistics of the aforementioned variablesÂ (weightage - 3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the plot size using figure()\n",
    "# pass width and height in inches to 'figsize' \n",
    "def outlier_treatment (df_sales) : \n",
    "    plt.figure(figsize = (15,8))\n",
    "\n",
    "    # code starts here\n",
    "    # plot a boxplot to visualize the outliers in all the numeric variables\n",
    "\n",
    "    \n",
    "     # code ends here\n",
    "    \n",
    "    # set plot label\n",
    "    # set text size using 'fontsize'\n",
    "    plt.title('Distribution of all Numeric Variables', fontsize = 15)\n",
    "\n",
    "    # xticks() returns the x-axis ticks\n",
    "    # 'rotation = vertical' rotates the x-axis labels vertically\n",
    "    plt.xticks(rotation = 'vertical', fontsize = 15)\n",
    "\n",
    "    # display the plot\n",
    "    plt.show()\n",
    "\n",
    "outlier_treatment (df_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_1(df_sales): \n",
    "    # code starts here\n",
    "    # add transpose() method\n",
    "    \n",
    "    return \n",
    "    # code ends here\n",
    "trans_1 = transpose_1(df_sales)\n",
    "trans_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.5â€¯Â Do outlier treatment. Take lower and upper bound based on Quartiles and 1.5 times IQR and then cap the outliers with the lower bound and upper bound values. (weightage - 6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier treatment function\n",
    "def treat_outliers_iqr(df, columns):\n",
    "    \"\"\"\n",
    "    Treats outliers in specified columns of a DataFrame using the IQR method.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list): A list of column names to treat outliers in.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with outliers treated.\n",
    "    \"\"\"\n",
    "    df_treated = df.copy()\n",
    "\n",
    "    # code starts here\n",
    "    # use for loop\n",
    "    \n",
    "    \n",
    "    return\n",
    "    # code ends here\n",
    "    \n",
    "columns_to_treat = df_sales.select_dtypes(include='number').columns\n",
    "df_treated = treat_outliers_iqr(df_sales, columns_to_treat)\n",
    "df_treated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.6â€¯ Run the â€˜describeâ€™ function on the treated data and note down the variables for which the â€˜maxâ€™ value has now changed post the outlier treatment (weightage - 2 marks)â€¯ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_2(df_treated): \n",
    "    \n",
    "    # code starts here\n",
    "\n",
    "    \n",
    "    return \n",
    "\n",
    "    # code ends here\n",
    "trans_2 = transpose_2(df_sales)\n",
    "trans_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.7â€¯Â Find the missing values. Note down the number of missing values for variable â€˜Genderâ€™Â (weightage - 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value (df_treated):\n",
    "    # code starts here\n",
    "    #  arrange sum of missing values in descending order\n",
    "\n",
    "    \n",
    "     \n",
    "    return \n",
    "    # code ends here\n",
    "\n",
    "missing_value (df_treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T1.8â€¯Â Drop the rows in which â€˜Genderâ€™ has missing values, recheck for missing values and note down the variable(s) that still has missing valuesÂ (weightage - 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_value(df_treated):\n",
    "    # code starts here\n",
    "    #Removing missing value row by Gender \n",
    "\n",
    "    # Check sum of missing values in the data (arrange in descending order)\n",
    "     \n",
    "    return \n",
    "    # code ends here\n",
    "remove_value(df_treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Carry out extensive data preparation and feature engineeringâ€¯(weightage - 15 marks)â€¯(ME) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â€¯T2.1â€¯ Do further univariate and multivariate analysis and convert the target variable into 0 and 1. (weightage -5 marks)â€¯ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Add 'Unit Price' variable and proceed with analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T2.2â€¯ Split the dataset into train and test.â€¯ (weightage -3 marks)â€¯ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T2.3â€¯ Create dummy variables and scale the numerical features (weightage-7 marks) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding,One hot encoding and scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Build and evaluate the models (weightage - 40 marks)â€¯ (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T3.1â€¯Â Build classification models (Logistic Regression, Decision Tree, Random Forest and at least two Boosting models is the minimum)Â (weightage-20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T3.2â€¯Â Check for the model evaluation parameters and do fine-tuning when necessary to make models free of errorsÂ (weightage-20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Summarize the findings of the analysis and draw conclusions with PPT / PDF. (weightage - 25 marks) (ME)â€¯â€¯ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Submission guidelines:â€¯â€¯â€¯ \n",
    "\n",
    "- Download the Jupyter notebook in the format of html.â€¯â€¯â€¯ \n",
    "\n",
    "- Upload it in the lumen (UNext LMS)â€¯â€¯ \n",
    "\n",
    "- Summarized PPT/ PDF prepared in Task 4 to be uploaded in the lumen (UNext LMS) and it must contain why and how the best model was selected. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
